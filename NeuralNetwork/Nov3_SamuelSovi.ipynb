{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Project: Neural Networks\n",
        "### by Samuel Sovi\n",
        "\n",
        "In this project I will be attempting to use the max temperature of a given day, the amount of precipitation and the wind speed to predict whether the minimum temperature is realtively cold or hot using a Neural Network.\n",
        "\n",
        "**Additional note**: a large portion of the code was taken from my Oct6 Project and I have used https://pytorch.org/tutorials/index.html as a reference for pytorch related things."
      ],
      "metadata": {
        "id": "aAB4HGqox7au"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Imports:\n",
        "I imported pandas for DataFrame access, numpy for calculations and arrays, tabulate for creating tables, and torch related imports for torch's neural network-related imports"
      ],
      "metadata": {
        "id": "JxzqJJfUyt9O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NR9W5dbiCWGb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tabulate import tabulate\n",
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
        "import torch.nn.functional as f"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I once again decided to use a github raw csv link for my data which I got from MeteoStat's API on RapidAPI last semester."
      ],
      "metadata": {
        "id": "JACeqwf5y7VP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_url = \"https://raw.githubusercontent.com/samps7/CSPC323_Files/main/weather_cleaned.csv\"\n",
        "\n",
        "data_df = pd.read_csv(data_url)"
      ],
      "metadata": {
        "id": "lU4d6I6xJcJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"original data\")\n",
        "print(data_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTucEYdHJcxx",
        "outputId": "f2ddd7be-21eb-45f0-8b04-71a2985451da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original data\n",
            "           date  tavg  tmin  tmax   prcp   wdir  wspd    pres\n",
            "0    2021-02-21  52.5  42.1  64.0  0.000  344.0   4.2  1030.0\n",
            "1    2021-02-22  56.5  45.0  72.0  0.000  354.0   3.6  1025.0\n",
            "2    2021-02-23  59.5  46.0  78.1  0.000  337.0   5.0  1020.0\n",
            "3    2021-02-24  57.6  43.0  71.1  0.000  351.0   6.8  1021.7\n",
            "4    2021-02-25  56.7  46.9  66.9  0.000  321.0   9.2  1023.7\n",
            "..          ...   ...   ...   ...    ...    ...   ...     ...\n",
            "360  2022-02-16  57.6  44.6  69.8  0.000  317.0   8.8  1017.4\n",
            "361  2022-02-17  58.1  48.2  68.0  0.000  295.0   5.3  1024.8\n",
            "362  2022-02-18  54.3  42.8  68.0  0.000  155.0   4.3  1024.3\n",
            "363  2022-02-19  56.7  44.6  69.8  0.000  317.0   4.4  1019.8\n",
            "364  2022-02-20  51.8  42.8  62.6  0.004  330.0   6.5  1015.4\n",
            "\n",
            "[365 rows x 8 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I start collecting my data from the dataset by obtaining the four columns that I am interested in: maximum temperature, precipitation, wind speed and minimum temperature (of each day)."
      ],
      "metadata": {
        "id": "WklIpHVxzo5a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# getting x and y values into arrays\n",
        "X_vals = data_df[[\"tmax\", \"prcp\", \"wspd\"]].copy().values\n",
        "y_vals = data_df[[\"tmin\"]].values\n",
        "\n",
        "colder_threshold = np.median(y_vals) #used later for differentiating \"warm\" vs cold temperatures"
      ],
      "metadata": {
        "id": "vNnko4uqJkPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I calculate 80% of the total number of days to take for training and randomly sample from the whole set"
      ],
      "metadata": {
        "id": "EhbAQz2pzsYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 50\n",
        "\n",
        "tensor_data = TensorDataset(torch.tensor(X_vals, dtype=torch.float32), torch.tensor(y_vals, dtype=torch.float32))\n",
        "\n",
        "row_count = X_vals.shape[0]\n",
        "\n",
        "train_percent = 0.2 # 20% used for testing\n",
        "\n",
        "test_size = int(row_count * train_percent) # size of testing set\n",
        "train_size = row_count - test_size # size of training set\n",
        "\n",
        "X_size = X_vals.shape[1]\n",
        "y_size = y_vals.shape[1]\n",
        "\n",
        "train_data, test_data = random_split(tensor_data, (train_size, test_size))\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size*2)\n",
        "\n",
        "print(\"training size:\", train_size,\"testing size:\", test_size)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tx45u88LcOQa",
        "outputId": "dac87d82-0118-416e-eb0a-18f45d062087"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training size: 292 testing size: 73\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "My Model class is for using torch's nn.Module as a subclass and training + testing values using a neural network"
      ],
      "metadata": {
        "id": "Vwg2GxCRz0bC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Model(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.linear = nn.Linear(X_size,y_size)\n",
        "  \n",
        "  def forward(self, xb):\n",
        "    output = self.linear(xb)\n",
        "    return output\n",
        "  \n",
        "  def train_step(self, batch):\n",
        "    inputs, targets = batch\n",
        "    output = self(inputs)\n",
        "    loss = f.l1_loss(output, targets)\n",
        "    return loss\n",
        "\n",
        "  def test_step(self, batch):\n",
        "    inputs, targets = batch\n",
        "    output = self(inputs)\n",
        "    loss = f.l1_loss(output, targets)\n",
        "    return {'loss' : loss.detach()}\n",
        "\n",
        "  def test_epoch_end(self, outputs):\n",
        "    batch_loss = [x['loss'] for x in outputs]\n",
        "    epoch_loss = torch.stack(batch_loss).mean()\n",
        "    return {'loss': epoch_loss.item()}\n",
        "\n",
        "  def epoch_end(self, epoch, result, num_epochs):\n",
        "    if (epoch+1) % 10 == 0 or epoch == num_epochs - 1:\n",
        "      print(\"Epoch #{} has loss: {:.4f}\".format(epoch, result['loss']))\n",
        "\n",
        "  \n"
      ],
      "metadata": {
        "id": "9CqCcG-Bdw96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_loss(model, test_loader):\n",
        "    outputs = [model.test_step(batch) for batch in test_loader]\n",
        "    return model.test_epoch_end(outputs)\n",
        "  \n",
        "def fit(epochs, learn_rate, model, train_loader, test_loader, optimize_ver=torch.optim.SGD):\n",
        "    hist = []\n",
        "    optimizer = optimize_ver(model.parameters(), learn_rate)\n",
        "    for epoch in range(epochs): \n",
        "        for batch in train_loader:\n",
        "            loss = model.train_step(batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "        result = show_loss(model, test_loader)\n",
        "        model.epoch_end(epoch, result,epochs)\n",
        "        hist.append(result)\n",
        "    return hist\n"
      ],
      "metadata": {
        "id": "0lLNna50hLs_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model()\n",
        "print(\"Original Loss: \\n\", show_loss(model, test_loader))\n",
        "learning_rate=1e-4 #said in class was best val?\n",
        "hist = fit(100, learning_rate, model, train_loader, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbuSlSmxjwtR",
        "outputId": "a1a3b8a9-29bf-4e1b-b493-faec54819246"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Loss: \n",
            " {'loss': 62.33405303955078}\n",
            "Epoch #9 has loss: 31.6444\n",
            "Epoch #19 has loss: 4.7446\n",
            "Epoch #29 has loss: 4.1981\n",
            "Epoch #39 has loss: 4.1951\n",
            "Epoch #49 has loss: 4.2022\n",
            "Epoch #59 has loss: 4.1982\n",
            "Epoch #69 has loss: 4.1891\n",
            "Epoch #79 has loss: 4.1700\n",
            "Epoch #89 has loss: 4.1648\n",
            "Epoch #99 has loss: 4.1762\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following is timing of my model's fitting (it also trains the model on the same data around 7 more times)"
      ],
      "metadata": {
        "id": "9tnPet1e1FM2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "hist = fit(100, learning_rate, model, train_loader, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Dses10z0b8O",
        "outputId": "c48b94a8-678f-499d-f761-0b787abd1bf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #9 has loss: 4.1627\n",
            "Epoch #19 has loss: 4.1592\n",
            "Epoch #29 has loss: 4.1520\n",
            "Epoch #39 has loss: 4.1481\n",
            "Epoch #49 has loss: 4.1456\n",
            "Epoch #59 has loss: 4.1393\n",
            "Epoch #69 has loss: 4.1356\n",
            "Epoch #79 has loss: 4.1173\n",
            "Epoch #89 has loss: 4.1228\n",
            "Epoch #99 has loss: 4.1159\n",
            "Epoch #9 has loss: 4.1210\n",
            "Epoch #19 has loss: 4.1068\n",
            "Epoch #29 has loss: 4.1021\n",
            "Epoch #39 has loss: 4.0978\n",
            "Epoch #49 has loss: 4.1008\n",
            "Epoch #59 has loss: 4.0989\n",
            "Epoch #69 has loss: 4.0888\n",
            "Epoch #79 has loss: 4.0791\n",
            "Epoch #89 has loss: 4.0904\n",
            "Epoch #99 has loss: 4.0815\n",
            "Epoch #9 has loss: 4.0739\n",
            "Epoch #19 has loss: 4.0762\n",
            "Epoch #29 has loss: 4.0685\n",
            "Epoch #39 has loss: 4.0652\n",
            "Epoch #49 has loss: 4.0617\n",
            "Epoch #59 has loss: 4.0655\n",
            "Epoch #69 has loss: 4.0565\n",
            "Epoch #79 has loss: 4.0489\n",
            "Epoch #89 has loss: 4.0498\n",
            "Epoch #99 has loss: 4.0466\n",
            "Epoch #9 has loss: 4.0431\n",
            "Epoch #19 has loss: 4.0385\n",
            "Epoch #29 has loss: 4.0388\n",
            "Epoch #39 has loss: 4.0419\n",
            "Epoch #49 has loss: 4.0331\n",
            "Epoch #59 has loss: 4.0274\n",
            "Epoch #69 has loss: 4.0230\n",
            "Epoch #79 has loss: 4.0298\n",
            "Epoch #89 has loss: 4.0169\n",
            "Epoch #99 has loss: 4.0123\n",
            "Epoch #9 has loss: 4.0077\n",
            "Epoch #19 has loss: 4.0160\n",
            "Epoch #29 has loss: 4.0117\n",
            "Epoch #39 has loss: 4.0009\n",
            "Epoch #49 has loss: 3.9981\n",
            "Epoch #59 has loss: 3.9987\n",
            "Epoch #69 has loss: 3.9971\n",
            "Epoch #79 has loss: 3.9932\n",
            "Epoch #89 has loss: 3.9924\n",
            "Epoch #99 has loss: 3.9945\n",
            "Epoch #9 has loss: 3.9875\n",
            "Epoch #19 has loss: 3.9859\n",
            "Epoch #29 has loss: 3.9820\n",
            "Epoch #39 has loss: 3.9835\n",
            "Epoch #49 has loss: 3.9752\n",
            "Epoch #59 has loss: 3.9749\n",
            "Epoch #69 has loss: 3.9674\n",
            "Epoch #79 has loss: 3.9710\n",
            "Epoch #89 has loss: 3.9665\n",
            "Epoch #99 has loss: 3.9710\n",
            "Epoch #9 has loss: 3.9707\n",
            "Epoch #19 has loss: 3.9644\n",
            "Epoch #29 has loss: 3.9617\n",
            "Epoch #39 has loss: 3.9637\n",
            "Epoch #49 has loss: 3.9559\n",
            "Epoch #59 has loss: 3.9534\n",
            "Epoch #69 has loss: 3.9513\n",
            "Epoch #79 has loss: 3.9535\n",
            "Epoch #89 has loss: 3.9396\n",
            "Epoch #99 has loss: 3.9522\n",
            "Epoch #9 has loss: 3.9441\n",
            "Epoch #19 has loss: 3.9501\n",
            "Epoch #29 has loss: 3.9533\n",
            "Epoch #39 has loss: 3.9455\n",
            "Epoch #49 has loss: 3.9416\n",
            "Epoch #59 has loss: 3.9317\n",
            "Epoch #69 has loss: 3.9282\n",
            "Epoch #79 has loss: 3.9383\n",
            "Epoch #89 has loss: 3.9266\n",
            "Epoch #99 has loss: 3.9276\n",
            "1.32 s ± 578 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "prediction method for use when predicting values later: (for my Confusion Matrix)"
      ],
      "metadata": {
        "id": "QLHzHoD10J2-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(x, model):\n",
        "    xb = x.unsqueeze(0)\n",
        "    return model(x).item()"
      ],
      "metadata": {
        "id": "9InE-es2lXME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sample of one testing case:\n",
        "\n",
        "x, target = test_data[0]\n",
        "pred = predict(x, model)\n",
        "print(\"\")\n",
        "print(\"Inputs (Max Temperature, Precipitation, Wind Speed): \", x)\n",
        "print(\"\")\n",
        "print(\"Actual Target Min Temperature: \", target.item())\n",
        "print(\"\")\n",
        "print(\"Model Prediction:\", pred)\n",
        "print(\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRSng4Z0lX4M",
        "outputId": "baa4867e-e0dd-4313-bb43-c24107001de4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Inputs (Max Temperature, Precipitation, Wind Speed):  tensor([70.0000,  0.0000,  2.1000])\n",
            "\n",
            "Actual Target Min Temperature:  43.0\n",
            "\n",
            "Model Prediction: 47.1186637878418\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following is timing of one predicion:"
      ],
      "metadata": {
        "id": "q-F7DTbl1Qk8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "pred = predict(x, model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L05xhx-n1TLV",
        "outputId": "a41b2603-9eb9-4bda-ba8a-44ddea1ef529"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47.1 µs ± 3.83 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following is getting all my predictions while using the same for loop to store all the actual values for later comparison:"
      ],
      "metadata": {
        "id": "nZDIquSD1aBh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = []\n",
        "actual = []\n",
        "\n",
        "for i in range(len(test_data)):\n",
        "  x, target = test_data[i]\n",
        "  pred = predict(x, model)\n",
        "\n",
        "  if target.item() > colder_threshold:\n",
        "    actual.append(False)\n",
        "  else:\n",
        "    actual.append(True)\n",
        "  \n",
        "  if pred > colder_threshold:\n",
        "    predictions.append(False)\n",
        "  else:\n",
        "    predictions.append(True)"
      ],
      "metadata": {
        "id": "xK5N-sCyqOx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(actual)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsmB3k9urO-a",
        "outputId": "ab4aafe6-3cb2-4652-e8c8-71e075b722e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[True, True, True, False, False, False, True, True, False, True, True, False, True, False, False, False, False, True, False, False, True, True, False, True, True, False, False, True, False, True, False, True, True, True, True, True, False, False, True, True, True, False, True, True, True, True, True, False, True, True, True, False, True, True, False, True, True, False, False, False, True, False, True, True, False, False, True, True, False, False, False, False, True]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3i2X3JjZrQX-",
        "outputId": "f9bc9402-2d00-48d1-bb27-a36300ec0cb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[True, True, True, False, False, True, True, True, False, True, True, True, True, False, False, False, False, True, False, False, True, True, False, True, True, False, False, True, False, True, False, True, False, True, True, True, False, False, True, True, True, False, True, False, True, False, False, False, True, True, True, False, True, True, False, True, True, False, False, False, True, False, False, True, False, False, True, False, True, False, True, True, True]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, I count the number of true/false positives and true/false negatives by iterating through both arrays"
      ],
      "metadata": {
        "id": "i3CmOVIn1n3t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_length = len(test_data)\n",
        "\n",
        "true_positive = 0\n",
        "false_positive = 0\n",
        "true_negative = 0\n",
        "false_negative = 0\n",
        "\n",
        "# counting true/false positve and true/false negatives:\n",
        "\n",
        "for i in range(test_length):\n",
        "  if actual[i] == False and predictions[i] == False:\n",
        "    true_negative = true_negative + 1\n",
        "  elif actual[i] == True and predictions[i] == True:\n",
        "    true_positive = true_positive + 1\n",
        "  elif actual[i] == False and predictions[i] == True:\n",
        "    false_positive = false_positive + 1\n",
        "  elif actual[i] == True and predictions[i] == False:\n",
        "    false_negative = false_negative + 1"
      ],
      "metadata": {
        "id": "aw5Ygz4srrLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tabulating data to make a Confusion Matrix:"
      ],
      "metadata": {
        "id": "yRBXFH3X1sCG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Confusion Matrix: for size\", test_length)\n",
        "\n",
        "result_table = [[\"\",\"PREDICTED COLDER = True\", \"PREDICTED COLDER = False\"], [\"ACTUAL COLDER = True\", true_positive, false_negative],\n",
        "                [\"ACTUAL COLDER = False\", false_positive, true_negative]]\n",
        "print(tabulate(result_table))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBs8biBkttYK",
        "outputId": "652c3da2-c220-4fa6-944b-867f925511e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix: for size 73\n",
            "---------------------  -----------------------  ------------------------\n",
            "                       PREDICTED COLDER = True  PREDICTED COLDER = False\n",
            "ACTUAL COLDER = True   35                       6\n",
            "ACTUAL COLDER = False  5                        27\n",
            "---------------------  -----------------------  ------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculating accuracy:"
      ],
      "metadata": {
        "id": "kR70TU2l10CX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = (true_positive + true_negative) / test_length\n",
        "\n",
        "print(\"accuracy =\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzF87eTi1xao",
        "outputId": "1662bcda-0db1-41a9-b2ba-851eae75ddf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy = 0.8493150684931506\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculating precision and recall:"
      ],
      "metadata": {
        "id": "JLTivsNK12kt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "precision = true_positive / (true_positive + false_positive)\n",
        "\n",
        "recall = true_positive / (true_positive + false_negative)\n",
        "\n",
        "print(\"precision = \", precision)\n",
        "\n",
        "print(\"recall = \", recall)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3u7K9P25ukZ4",
        "outputId": "dcb3372d-b050-4aab-fda5-afb6814be73a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "precision =  0.875\n",
            "recall =  0.8536585365853658\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculating $F_1$:"
      ],
      "metadata": {
        "id": "2sB-0Vz314xN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f_1 = 2 / (1/recall + 1/precision)\n",
        "print(\"f_1 =\", f_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ya26Ualmumn0",
        "outputId": "f37f1931-03fa-4d33-cbfa-e038a0971954"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f_1 = 0.8641975308641976\n"
          ]
        }
      ]
    }
  ]
}